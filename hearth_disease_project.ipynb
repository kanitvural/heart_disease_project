{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Projesi: Kardiyovasküler Hastalık Tahmini\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proje Açıklaması\n",
    "Bu projede, kardiyovasküler hastalıkları tahmin etmek için bir makine öğrenmesi modeli geliştirilecektir. Verilen veri seti, çeşitli hasta özelliklerini ve bu hastaların kardiyovasküler hastalık durumu hakkında bilgi içermektedir. Amaç, bu veri setini kullanarak hastalık tahmin doğruluğunu artırmak için gerekli veri işleme ve özellik mühendisliği adımlarını gerçekleştirmektir.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kullanılacak veri seti: [Heart Disease Dataset](https://archive.ics.uci.edu/dataset/45/heart+disease)\n",
    "\n",
    "Kurulum:\n",
    "```pip install ucimlrepo```\n",
    "\n",
    "Kullanım:\n",
    "```\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "# metadata \n",
    "print(heart_disease.metadata) \n",
    "# variable information \n",
    "print(heart_disease.data.variables)\n",
    "heart_disease.variables)\n",
    "```\n",
    "\n",
    "**Veri setinin Özelliklerinin açıklamaları:**\n",
    "\n",
    "1. **Age: Yaş** - Kişinin yaşı hakkında sayısal bilgi içerir.\n",
    "2. **Sex: Cinsiyet** - Kişinin cinsiyetini belirtir (1 = erkek; 0 = kadın).\n",
    "3. **Chest Pain Type (4 values)** - Göğüs ağrısı türünü belirtir (1: Tipik angina, 2: Atipik angina, 3: Non-anginal ağrı, 4: Asemptomatik).\n",
    "4. **Resting Blood Pressure** - Dinlenme halindeki kan basıncı (mm Hg cinsinden).\n",
    "5. **Serum Cholesterol in mg/dl** - Serum kolesterol düzeyi (mg/dl cinsinden).\n",
    "6. **Fasting Blood Sugar > 120 mg/dl** - Açlık kan şekeri seviyesi 120 mg/dl'nin üzerinde mi (1 = doğru; 0 = yanlış).\n",
    "7. **Resting ECG results (values 0, 1, 2)** - Dinlenme halindeki elektrokardiyografi sonuçları (0: Normal, 1: ST-T dalga anormallikleri, 2: Sol ventrikül hipertrofisi veya T dalga inversiyonu).\n",
    "8. **Maximum Heart Rate achieved** - Ulaşılan maksimum kalp hızı.\n",
    "9. **Exercise Induced Angina** - Egzersizle indüklenen angina (1 = evet; 0 = hayır).\n",
    "10. **ST depression induced by exercise relative to rest** - Egzersizle indüklenen ST segmenti depresyonu (dinlenmeye göre).\n",
    "11. **Slope of the peak exercise ST segment** - Egzersiz sırasında zirve ST segmentinin eğimi (1: Yukarı eğimli, 2: Düz, 3: Aşağı eğimli).\n",
    "12. **Number of major vessels (0-3) colored by fluoroscopy** - Floroskopi ile boyanmış ana damar sayısı (0-3 arası).\n",
    "13. **Thal** - Talasemi durumu (3 = normal; 6 = sabit defekt; 7 = geri dönebilen defekt).\n",
    "\n",
    "---\n",
    "\n",
    "**Hedef değişken**: Presence of heart disease (Kalp hastalığı varlığı) - Kalp hastalığı olup olmadığını belirtir (1 = hastalık; 0 = hastalık yok).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Sayısal ve kategorik özellikler**\n",
    "\n",
    "**Sayısal özellikler**\n",
    "- age: integer\n",
    "- resting_blood_pressure: integer\n",
    "- serum_cholesterol: integer\n",
    "- maximum_heart_rate_achived\n",
    "- st_depression_induced_by_exercise\n",
    "- number_major_vessels\n",
    "\n",
    "**Sayısal kategorik özellikler**\n",
    "- sex\n",
    "- chest_pain_type\n",
    "- fasting_blood_sugar\n",
    "- resting_ecg_results\n",
    "- exercise_induced_angina\n",
    "- thal\n",
    "- slope_peak_exercise_st_segment\n",
    "- presence_of_heart_disease (Target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kütüphane importları**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, roc_auc_score, roc_curve,auc, confusion_matrix, make_scorer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "plt.style.use(\"ggplot\")\n",
    "sns.set_palette(sns.diverging_palette(220, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Yükleme ve Temizleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- İlk olarak veri kaynaktan indirilmiş, ardından özellikler proje word dosyasında bulunan özellikler ile karşılaştırılıp doğrulanmış ve özelliklere proje word dosyasındaki özellik isimleri verilmiştir.\n",
    "  \n",
    "- Kaynaktan gelen veriler dataframe haline getirilmiştir. Kolon isimlendirmeleri yapıldıktan sonra tekrar raw_df adında csv dosyasına kaydedilmiştir. Buradaki amaç, notebook dosyasının baştan çalıştırması durumunda veriyi internetten tekrar indirmek yerine csv den okumaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataseti indirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heart_disease = fetch_ucirepo(id=45)\n",
    "# X = heart_disease.data.features \n",
    "# y = heart_disease.data.targets \n",
    "# df = pd.concat([X, y], axis=1)\n",
    "# print(\"Veri seti boyutu\")\n",
    "# print(heart_disease.data.features.shape)\n",
    "# print(heart_disease.data.targets.shape)\n",
    "# print(\"---------------------------------\")\n",
    "# print(\"İnternetten okunan verinin kolon isimleri ve tipleri:\")\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Word dosyasındaki isimlendirme ile csv kayıt işlemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_rename_dict={\n",
    "#     \"age\":\"age\",\n",
    "#     \"sex\":\"sex\",\n",
    "#     \"cp\":\"chest_pain_type\",\n",
    "#     \"trestbps\":\"resting_blood_pressure\",\n",
    "#     \"chol\":\"serum_cholesterol\",\n",
    "#     \"fbs\":\"fasting_blood_sugar\",\n",
    "#     \"restecg\":\"resting_ecg_results\",\n",
    "#     \"thalach\":\"maximum_heart_rate_achieved\",\n",
    "#     \"exang\":\"exercise_induced_angina\",\n",
    "#     \"oldpeak\":\"st_depression_induced_by_exercise\",\n",
    "#     \"slope\":\"slope_peak_exercise_st_segment\",\n",
    "#     \"ca\":\"number_major_vessels\",\n",
    "#     \"thal\":\"thal\",\n",
    "#     \"num\":\"presence_of_heart_disease\"\n",
    "# }\n",
    "# df = df.rename(columns=columns_rename_dict)\n",
    "\n",
    "# # hedef değişken binary tipe dönüştürüldü.\n",
    "# df[\"presence_of_heart_disease\"] = np.where(df[\"presence_of_heart_disease\"] > 1, 1, 0)\n",
    "# df.to_csv(\"raw_heart_disease_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num yani Presence of heart disease hedef değişkeni 5 klasdan oluşmaktadır. Canlı dersde bu değişkenin 0 ve 1 olarak değerlendirilmesi istendiği. Bu nedenle 1 üzerindeki değerlerinde yine 1 olarak alınacağı belirtildiğinden dolayı hedef  bu şekilde düzenlenmiştir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verinin lokalden yüklenmesi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_heart_disease_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eksik Veri İşlemleri**\n",
    "- number_major_vessels de 4 ve thal da 2 adet eksik veri tespit edilmiştir.\n",
    "- Bir veri setinde bulunan eksik veriler için dünyada kabul gören %5 kuralına göre eksik veriler veri setinin %5 inden az ise bu verileri kaldırmak genelde uygulanan bir yaklaşımdır.\n",
    "\n",
    "\n",
    "\n",
    "- Heart-disease veri setinde bu oran yaklaşık 1.98 olduğundan eksik veriler temizleniştir.\n",
    "$$\n",
    "\\text{Eksik veri oranı} = \\left(\\frac{6}{303}\\right) \\times 100 \\approx 1.98\\%\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eksik verilerin temizlenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tekrarlanan veri kontrolü**\n",
    "- Veri setinde tekrarlanan veri bulunmamaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anormal değerlerin tespiti**\n",
    "\n",
    "- Anormal değerlerin tespiti işleminden önce plotting fonksiyonu tanımlanmış veriler analiz edilmiştir.\n",
    "  \n",
    "- Veri setinde object veya categorical tipde veri olmadığından. Sayısal verileri görselleştirmek amaçlı yazılmıştır. Dağılımlar için histogram ve kdeplot, aykırı değer tespiti için boxplot çizimi yapılmaktadır.\n",
    "  \n",
    "- Dağılımlar incelenmiştir.\n",
    "  \n",
    "- Anormal değerlerin tespiti için fonksiyon yazılmıştır. Veri setindeki her bir sayısal özellik için girilen eşik değere göre alt ve üst limitleri geri dönmektedir. Ayrıca describe ve outliers i göstermek için kolaylaştırıcı fonksiyonlar yazılmıştır.\n",
    "  \n",
    "-  Tespit edilen aykırı değerler alt limit yada üst limit değerlerine baskılanmıştır.\n",
    "  \n",
    "-  Sayısal kategorik değişkenlerin sınıfları veri setinden kontrol edilip doğrulamaları yapılmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonksiyon tanımlamaları**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df,types=[\"int64\",\"float64\"]):\n",
    "   numeric_columns= [col for col in df.columns if df[col].dtype in types]\n",
    "   for i in numeric_columns:\n",
    "      fig, axes = plt.subplots(nrows=1,ncols=3, figsize=(20,4))\n",
    "      sns.histplot(x=df[i],bins=10,ax=axes[0])\n",
    "      axes[0].set_title(i)\n",
    "      sns.boxplot(x=df[i],ax=axes[1])\n",
    "      axes[1].set_title(i)\n",
    "      sns.kdeplot(x=df[i],ax=axes[2])\n",
    "      axes[2].set_title(i)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diğer plot fonksiyonuda barplotun özelleştirilmiş halidir kategorik bir özelliğin sayısal bir özelliğe karşı durumunu görselleştirmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_barplot(df, categoric_value, numeric_value, agg_func):\n",
    "    sorted_df = df.groupby(categoric_value)[numeric_value].agg(agg_func).reset_index().sort_values(numeric_value, ascending=False)\n",
    "    sns.barplot(x=categoric_value, y=numeric_value, data=df, estimator=agg_func, order=sorted_df[categoric_value], ci=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(df, variable, q1_thr=0.25, q3_thr=0.75):\n",
    "    quartile1 = df[variable].quantile(q1_thr)\n",
    "    quartile3 = df[variable].quantile(q3_thr)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    print(f\"low_limit: {low_limit}, up_limit: {up_limit}\")\n",
    "    return low_limit, up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_feature(df, feature):\n",
    "    print(f\"Veri tipi: {df[feature].dtypes}\")\n",
    "    return df[[feature]].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_categorical_feature(df, feature, normalize=False):\n",
    "    print(f\"Veri tipi: {df[feature].dtypes}\")\n",
    "    return df[feature].value_counts(normalize=normalize).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_outliers(df, feature, low_limit, up_limit, head_num = 5):\n",
    "    df = df[(df[feature] < low_limit) | (df[feature] > up_limit)]\n",
    "    print(f\"Veri setinde {len(df)} adet aykırı değer bulunmaktadır.\")\n",
    "    return df.head(head_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sayısal özellikler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"resting_blood_pressure\",\n",
    "    \"serum_cholesterol\",\n",
    "    \"maximum_heart_rate_achieved\",\n",
    "    \"st_depression_induced_by_exercise\",\n",
    "    \"number_major_vessels\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numeric_features].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dağılımlar incelendiğinde age, resting bolood pressure özelliklerinin normale yakın dağıldığı, serum cholesterolun hafif sağa çarpık olduğu, maximum healt rate achived hafif sola çarpık olduğu, st_depression induced by exercise yüksek oranda sağa çarpık olduğu gözlemlenmiştir.**\n",
    "\n",
    "**Değişkenlerin özet istatistikleri mean ve medyan değerleri incelendiğindede bu durum gözlenmektedir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age**\n",
    "\n",
    "- Age değişkenindeki değerler normal görünmektedir aykırı değer bulunmamaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit, up_limit = outlier_thresholds(df, \"age\")\n",
    "show_outliers(df,\"age\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resting blood pressure**\n",
    "\n",
    "- Üst limit değerinin üzerinde 9 adet aykırı değer tespit edilmiş ve üst limit değerine baskılanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df,\"resting_blood_pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit, up_limit = outlier_thresholds(df, \"resting_blood_pressure\")\n",
    "show_outliers(df,\"resting_blood_pressure\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aykırı değer baskılama.\n",
    "df.loc[(df[\"resting_blood_pressure\"] > up_limit), \"resting_blood_pressure\"] = up_limit\n",
    "show_outliers(df,\"resting_blood_pressure\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**serum_cholesterol**\n",
    "\n",
    "- Üst limit değerinin üzerinde 5 adet aykırı değer tespit edilmiş ve üst limit değerine baskılanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df,\"serum_cholesterol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit, up_limit = outlier_thresholds(df, \"serum_cholesterol\")\n",
    "show_outliers(df,\"serum_cholesterol\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aykırı değer baskılama.\n",
    "df.loc[(df[\"serum_cholesterol\"] > up_limit), \"serum_cholesterol\"] = up_limit\n",
    "show_outliers(df,\"serum_cholesterol\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**maximum_heart_rate_achieved**\n",
    "\n",
    "- Alt limit değerinin altında 1 adet aykırı değer tespit edilmiş ve alt limit değerine baskılanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df,\"maximum_heart_rate_achieved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit, up_limit = outlier_thresholds(df, \"maximum_heart_rate_achieved\")\n",
    "show_outliers(df,\"maximum_heart_rate_achieved\", low_limit, up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aykırı değer baskılama.\n",
    "df.loc[(df[\"maximum_heart_rate_achieved\"] < low_limit), \"maximum_heart_rate_achieved\"] = low_limit\n",
    "show_outliers(df,\"maximum_heart_rate_achieved\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**st_depression_induced_by_exercise**\n",
    "\n",
    "- Üst limit değerinin üzerinde 5 adet aykırı değer tespit edilmiş ve üst limit değerine baskılanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_feature(df,\"st_depression_induced_by_exercise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_limit, up_limit = outlier_thresholds(df, \"st_depression_induced_by_exercise\")\n",
    "show_outliers(df,\"st_depression_induced_by_exercise\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aykırı değer baskılama.\n",
    "df.loc[(df[\"st_depression_induced_by_exercise\"] > up_limit), \"st_depression_induced_by_exercise\"] = up_limit\n",
    "show_outliers(df,\"st_depression_induced_by_exercise\", low_limit, up_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**number_major_vessels**\n",
    "\n",
    "- 0 ile 3 arasında değer alan floroskopi ile boyanmış damar sayısını ifade eden kesikli sayısal değişkendir. Damar sayısının 0 ile 3 arası değer aldığı doğrulanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"number_major_vessels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Aykırı değer işlemleri neticesinde dağılımlarda azda olsa düzelmeler gözlemlenmiştir. Özellikle serum cholestrol özelliği normale yaklaşmıştır.**\n",
    "- **Sağa ve sola çarpık verilerin olduğu bu datasette model performanslarını artırmak amacı ile modelleme aşamasında scaling(ölçekleme) yapılacaktır.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sayısal kategorik değişkenlerin doğrulaması**\n",
    "- Kategorilerde farklı bir değer yoktur. Doğrulama yapılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_categorical_features = [\n",
    "    \"sex\",\n",
    "    \"chest_pain_type\",\n",
    "    \"fasting_blood_sugar\",\n",
    "    \"resting_ecg_results\",\n",
    "    \"exercise_induced_angina\",\n",
    "    \"thal\",\n",
    "    \"slope_peak_exercise_st_segment\",\n",
    "    \"presence_of_heart_disease\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numeric_categorical_features:\n",
    "    print(df[[feature]].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kategorik değişkenlerin encode edilmesi**\n",
    "\n",
    "- Kategorik değişkenler tek tek incelenip uygun encoding metodları uygulanmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sex**\n",
    "\n",
    "- Erken ve kadın değerleri veri setinde  0 ve 1 olarak encode edilmiş haldedir. İlave bir işlem yapılmamıştır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chest pain type**\n",
    "\n",
    "- Göğus ağrısı tiplerini ifade eder. Açıklamalardan görüldüğü üzere göğüs ağrısı tipleri arasında büyüklük küçüklük ilişkisi yoktur. Bunlar nominal kategorik değişkenlerdir. Bu nedenle one hot encoding yönteminin uygulanması daha uygun olacaktır.\n",
    "  \n",
    "- İlk önce rakamların hangi değerlere karşılık geldiği maplenip sonra one hot encoing yapılmıştır.\n",
    "\n",
    "- **1: Typical angina (Tipik anjina)**: \n",
    "    - Genellikle fiziksel aktivite veya stres sırasında ortaya çıkan ve dinlenme veya nitrogliserin ile hafifleyen göğüs ağrısı.\n",
    "    - Kalp ile ilgili olduğu düşünülür.\n",
    "- **2: Atypical angina (Atipik anjina)**: \n",
    "    - Tipik anjinaya benzer ancak semptomlar ve tetikleyiciler açısından farklılık gösterir.\n",
    "    - Kalp ile ilgili olabilir veya olmayabilir.\n",
    "- **3: Non-anginal pain (Non-anjiinal ağrı)**: \n",
    "    - Göğüs ağrısı, ancak tipik anjinaya benzemeyen ve genellikle kalp ile ilgili olmayan ağrılar.\n",
    "    - Örneğin, kas veya iskelet sistemi kaynaklı olabilir.\n",
    "- **4: Asymptomatic (Asemptomatik)**: \n",
    "    - Göğüs ağrısı olmadan kalp hastalığı veya benzeri durumlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"chest_pain_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_pain_type_dict = {\n",
    "    1 :\"cp_typical_angina\",\n",
    "    2 :\"cp_atypical_angina\",\n",
    "    3 :\"cp_non_anginal_pain\",\n",
    "    4: \"cp_asymptomatic\"\n",
    "}\n",
    "df[\"chest_pain_type\"] = df[\"chest_pain_type\"].map(chest_pain_type_dict)\n",
    "describe_categorical_feature(df, \"chest_pain_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_one_hot = pd.get_dummies(df[\"chest_pain_type\"]).astype(int)\n",
    "df.drop(\"chest_pain_type\", axis=1,inplace=True)\n",
    "df=pd.concat([df,category_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fasting_blood_sugar**\n",
    "\n",
    "- Açlık kan şekeri değeri > 120 mg/dl üzerinde ise 1 değilse 0 olarak kodlanmış haldedir. İlave işleme gerek görülmemiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"fasting_blood_sugar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**resting_ecg_results**\n",
    "\n",
    "- Dinlenme EKG sonuçlarını ifade eder. Açıklamalardan görüldüğü üzere arasında büyüklük küçüklük ilişkisi yoktur. Bunlar nominal kategorik değişkenlerdir. Bu nedenle one hot encoding yönteminin uygulanması daha uygun olacaktır.\n",
    "\n",
    "**0: Normal**:\n",
    "- Kalp elektrokardiyogramında (EKG) herhangi bir anormallik göstermeyen, normal bir ST-T dalga şekli.\n",
    "\n",
    "**1: ST-T Dalga Anormalliği**:\n",
    "- ST-T dalgasında anormallikler bulunur; bu, T dalgası inversiyonu ve/veya ST segmentinde > 0.05 mV yükselme veya çöküşü içerebilir.\n",
    "\n",
    "**2: Muhtemel veya Kesin Sol Ventrikül Hipertrofisi**:\n",
    "- Estes kriterlerine göre sol ventrikül hipertrofisini gösteren bir EKG bulgusu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"resting_ecg_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_results_dict = {\n",
    "    0: \"ecg_normal\",\n",
    "    1: \"ecg_st_t_wave_abnormality\",\n",
    "    2: \"ecg_left_ventricular_hypertrophy\"\n",
    "}\n",
    "df[\"resting_ecg_results\"] = df[\"resting_ecg_results\"].map(ecg_results_dict)\n",
    "describe_categorical_feature(df, \"resting_ecg_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_one_hot = pd.get_dummies(df[\"resting_ecg_results\"]).astype(int)\n",
    "df.drop(\"resting_ecg_results\", axis=1,inplace=True)\n",
    "df=pd.concat([df,category_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**exercise_induced_angina**\n",
    "\n",
    "- Egzersiz sonucu ortaya çıkan anjina (göğüs ağrısı). Bu, fiziksel aktivite veya stres sırasında göğüs ağrısının meydana gelmesini ifade eder. Yine veri setinde egzersiz sonrası ağrı varsa 1 yoksa 0 olarak kodlandığından ilave işlem yapılmamıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"exercise_induced_angina\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**thal**\n",
    "\n",
    "**thal:** Thallium stres testi sonuçlarını ifade eder. Bu test, kalp kasının kan akışını ve oksijenlenmesini değerlendirmek için kullanılır. Test, kalp kasının bazı bölgelerinde kan akışının yeterliliğini incelemek amacıyla yapılır. Aralarında büyüklük küçüklük ilişkisi yoktur. Bunlar nominal kategorik değişkenlerdir. Bu nedenle one hot encoding yönteminin uygulanması daha uygun olacaktır.\n",
    "\n",
    "**Thallium Stresi Testi Sonuçları:**\n",
    "\n",
    "**3: Normal**:\n",
    "- Kalp kasının kan akışında herhangi bir anormallik göstermeyen, normal bir durum.\n",
    "\n",
    "**6: Sabit Defekt**:\n",
    "- Kalp kasında egzersiz veya ilaç tedavisi ile iyileşmeyen kalıcı bir defekt veya hasar. Bu, kalpteki belirli bölgelerde kalıcı bir bozukluğu ifade eder.\n",
    "\n",
    "**7: Geri Dönüşlü Defekt**:\n",
    "- Kalp kasında egzersiz veya ilaç tedavisi sonrası iyileşebilen geçici bir defekt veya hasar. Bu, tedavi veya egzersiz sonrası düzelebilen bir bozukluğu ifade eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"thal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thal_dict = {\n",
    "    3: \"thal_normal\",\n",
    "    6: \"thal_fixed_defect\",\n",
    "    7: \"thal_reversable_defect\"\n",
    "}\n",
    "df[\"thal\"] = df[\"thal\"].map(thal_dict)\n",
    "describe_categorical_feature(df, \"thal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_one_hot = pd.get_dummies(df[\"thal\"]).astype(int)\n",
    "df.drop(\"thal\", axis=1,inplace=True)\n",
    "df=pd.concat([df,category_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**slope_peak_exercise_st_segment**\n",
    "\n",
    "**slope:** Egzersiz sırasında ST segmentinin eğimi. Bu, bir elektrokardiyogram (EKG) üzerinde egzersiz sırasında ST segmentindeki değişiklikleri ölçer. ST segmentinin fiziksel aktiviteye nasıl yanıt verdiğini değerlendirmeye yardımcı olur. Yine one hot encoding ile encode etmek uygun olacaktır.\n",
    "\n",
    "\n",
    "**Slope of Peak Exercise ST Segment Values:**\n",
    "\n",
    "**1: Upsloping**:\n",
    "- ST segmentin egzersiz sırasında yukarı doğru eğimli olduğu durum. Genellikle iyi bir kalp kası kan akışını ve uygun kalp fonksiyonunu gösterir.\n",
    "\n",
    "**2: Flat**:\n",
    "- ST segmentin egzersiz sırasında düz olduğu durum. Bu, kalp kasında yeterli kan akışı olup olmadığını anlamak için dikkatli değerlendirilmesi gereken bir durumdur.\n",
    "\n",
    "**3: Downsloping**:\n",
    "- ST segmentin egzersiz sırasında aşağıya doğru eğimli olduğu durum. Genellikle kalp kasında potansiyel bir sorun veya oksijen yetersizliği işareti olabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"slope_peak_exercise_st_segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_dict = {\n",
    "    1: \"slope_upsloping\",\n",
    "    2: \"slope_flat\",\n",
    "    3: \"slope_downsloping\"\n",
    "}\n",
    "df[\"slope_peak_exercise_st_segment\"] = df[\"slope_peak_exercise_st_segment\"].map(slope_dict)\n",
    "describe_categorical_feature(df, \"slope_peak_exercise_st_segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_one_hot = pd.get_dummies(df[\"slope_peak_exercise_st_segment\"]).astype(int)\n",
    "df.drop(\"slope_peak_exercise_st_segment\", axis=1,inplace=True)\n",
    "df=pd.concat([df,category_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**presence_of_heart_disease (Target)**\n",
    "\n",
    "**`presence_of_heart_disease`** değişkeni, kalp hastalığının varlığını belirlemek için kullanılan bir hedef değişkendir. \n",
    "\n",
    "**`presence_of_heart_disease` (Hedef)**:\n",
    "\n",
    "- **0**: Kalp hastalığı yok.\n",
    "- **1**: Kalp hastalığı var.\n",
    "\n",
    "Bu değişken, genellikle tıbbi verilerde kalp hastalığını tahmin etmek için kullanılan bir hedef değişken olup, modelin sonuçlarını değerlendirmek amacıyla kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"presence_of_heart_disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding işlemleri tamamlanmıştır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faeture Extraction (Özellik Çıkarımı)**\n",
    "\n",
    "- Bu kısımda veri setindeki değişkenler kullanılarak. Modelin daha performanslı çaçışmasını sağlayacak yeni değişkenler türetilecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daha ssonra burayı yap, özellik çıkarmak için keşifsel veri analizi aşamaları olabilir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "**Korelasyon Analizi**\n",
    "\n",
    "- Hedef değişkenimiz presence_of_heart_disease dir. Bu değişken ile diğer sayısal değişkenlerin arasında bir korelasyon olup olmadığı analiz edilmiştir. \n",
    "\n",
    "**Pairplot**\n",
    "\n",
    "- Bütün özelliklerin görselleştirilmesi uzun sürdüğü ve okunabilir olmadığı için sadece sayısal değişkenler görselleştirilmiştir.\n",
    "- age ile maximum_heart_rate_achieved arasında güçlü negatif korelasyon göze çarpmaktadır, \n",
    "- yine age ile serum kolestrol arasında güçlü olabilecek bir ilişki gözlemlenmektedir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 15))\n",
    "sns.pairplot(data=df[numeric_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 15))\n",
    "num_variables = df.select_dtypes(include=[\"float64\",\"int64\"])\n",
    "corr_df = num_variables.corr()\n",
    "mask = np.triu(np.ones_like(corr_df, dtype=bool))\n",
    "tri_df = corr_df.mask(mask)\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "sns.heatmap(tri_df,annot=True,fmt=\".2f\",cmap = cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap incelemesi ve birbiri arasında korelasyonlu değişkenlerin tespiti**\n",
    "\n",
    "- Burada görselin daha anlaşılır olması için np.triu ile ones_like birlikte kullanılarak bool değerler oluşurup üst üçgenin gösterilmemesini sağlanmıştır.\n",
    "Aşağıda heatmapi incelediğimizde korelasyonlar renkler ile açıkça görülmektedir. Kırmızılar pozitif maviler negatif korelasyonları temsil etmektedir.\n",
    "\n",
    "Değişkenler arasında %70 den fazla korelasyonu olanlar multicollinearity problemi oluşmaması için korelasyonlu olanları biri kullanılmayacaktır.\n",
    "Yüksek korelasyonlu değişkenler aynı bilgiyi ifade ettiklerinden aralarındaki küçük farklar makine öğrenimi modelini yanıltabilir. Bu nedenle bu değişkenlerin çıkarılması model performansını artırabilir.\n",
    "\n",
    "Bu değişkenler:\n",
    "- ecg_normal - ecg_left_ventricular_hypertropy: -0.97 lik çok yüksek negatif korelasyon vardır. ecg_left_ventricular_hypertrophy özelliği çıkarılmıştır.\n",
    "- thal_mormal - thal_reversible_defect: -0.88 lik çok yüksek negatif korelasyon vardır. thal_reversable_defect özelliği çıkarılmıştır.\n",
    "- slope_flat - slope_upsloping: -0.87 lik çok yüksek negatif korelasyon vardır. slope_upsloping özelliği çıkarılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featueres_high_corr = [\"ecg_left_ventricular_hypertrophy\",\"thal_reversable_defect\",\"slope_upsloping\"]\n",
    "df.drop(featueres_high_corr, axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hedef özellik (presence_of_heart_disease) ile diğer özelliklerin arasındaki korelasyonların tespiti**\n",
    "- Burada target değişken presence_of_heart_disease ile sayısal değişkenlerin korelasyonuna bakılmıştır. Eşik değer 0.05 korelasyonlu olarak belirlenmiş ve görselleştirilmiştir. \n",
    "- İlk önce birbiri ile korelasyonlu değişkenler kaldırılıp tam olarak hedef değişken ile korelasyonlu değişkenlerin kaç adet olduğu tespit edilmiştir. \n",
    "- Target değişken ile bağımsız değişkenler arasında 0.05 korelasyondan yüksek 13 özellik tespit edilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "tri_df[\"presence_of_heart_disease\"].drop(\"presence_of_heart_disease\").sort_values().plot(kind=\"bar\")\n",
    "plt.axhline(0.05, color =\"red\",linestyle ='--')\n",
    "plt.axhline(-0.05, color='red',linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(tri_df[\"presence_of_heart_disease\"])\n",
    "cor_target.drop(\"presence_of_heart_disease\",inplace=True,axis=0)\n",
    "correlated_features  = cor_target[cor_target >=0.05]\n",
    "print(\"Toplam özellik sayısı:\",len(df.select_dtypes(include=[\"float64\",\"int64\"]).columns))\n",
    "print(\"Korelasyonlu özellik sayısı:\",len(correlated_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Oluşturma ve Değerlendirme\n",
    "\n",
    "### Bu bölüm altında projede istenen scaling, normalization, sampling işlemleri ilgili yerlerde yapılacaktır.\n",
    "\n",
    "**Kullanılacak Modellerin Seçimi**\n",
    "\n",
    "- presence_of_heart_disease yani kişinin kalp hastası olup olmadığının tahmin edilmesi, makine öğreniminde binary sınıflandırma problemidir. \n",
    "  \n",
    "- Occam's razor yani basitmodelden karmaşık modele gitme prensibinden dolayı ilk olarak Lojistik Regresyon modeli kullanılmıştır. Veri setinde güçlü doğrusal korelasyonlar bulunduğundan iyi performans gösterebilir. Logistic regresyonu ayrıca tek neronlu basit bir sinir ağı olarakda düşünebiliriz. Loss(kayıp) fonksiyonu olarak katsayıların güncellenmesinde binary crossentropy fonksiyonu kullanılır. \n",
    "  \n",
    "- İkinci model olarak ağaç tabanlı bir model kullanılması tercih edilmiştir. Ağaç tabanlı modellerden de boosting(örn: xgboost), bagging(bootstrap aggregation) modelleri(örn: random forest) arasında seçim yapılması gerektiğinde RandonForestClassifier modeli tercih edilmiştir. Bunun nedenide boosting algoritmaları özelliklede xgboost yüksek boyutlu veri setlerinde daha iyi performans gösterirler. Projemizdeki veri seti çok küçük olduğundan overfitting(aşırı uyum) olma ihtimali dahada artabileceğinden karşılaştırma modeli olarak Random Forests Classifier'ı seçilmiştir. \n",
    "  \n",
    "- Ağaç tabanlı model seçilmesinin bir diğer nedenide sınıf dengesizliği sorununu ele alabilir ve dengesiz veri setlerinde iyi performans gösterebilir. Ayrıca, tek bir ağaç modeli yerine, birçok bağımsız zayıf ağacın ortak kararıyla sonuç üreten ve kalabalık bilgeliği prensibine dayanan sıklıkla kullanılan bir model olan Random Forest Classifier kullanılmıştır. Ayrıca ağaç tabanlı modeller ölçeklemeye karşıda dirençlidir. Veri seti ölçeklenmedende kullanılabilir.\n",
    "  \n",
    "-  Her iki modelin de sınıf dengesizliklerini class_weights parametresi ile ele alması ve düşük yoğunluklu sınıflara önem vererek ele almaktadır. \n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Değerlendirme Metriklerinin Seçimi**\n",
    "\n",
    "İlk metrik seçimi için önemli olabilecek 2 metrik için değerlendirme yapılmıştır. \n",
    "\n",
    "**Precision (Kesinlik):**\n",
    "\n",
    "- **Tanım:** Doğru pozitif tahminlerin, tüm pozitif tahminlere (doğru pozitif + yanlış pozitif) oranıdır.\n",
    "- **Formül:**\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "- **Anlamı:** Modelin pozitif sınıfa (kalp hastalığı) ait olarak sınıflandırdığı hastaların ne kadarının gerçekten kalp hastalığına sahip olduğunu gösterir.\n",
    "- Eğer yanlış pozitifler (kalp hastası olarak yanlış sınıflandırılan sağlıklı bireyler) ciddi sonuçlara yol açıyorsa, precision daha önemli olabilir. Örneğin, hastalara gereksiz tedavi veya endişe vermemek için, yanlış pozitiflerin sayısını azaltmak önemlidir.\n",
    "\n",
    "**Recall (Duyarlılık):**\n",
    "\n",
    "- **Tanım:** Gerçek pozitiflerin (kalp hastalığı olanlar) tüm pozitif durumlara (gerçek pozitif + yanlış negatif) oranıdır.\n",
    "- **Formül:**\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "- **Anlamı:** Gerçek kalp hastalığı olan hastaların ne kadarının doğru bir şekilde tespit edildiğini gösterir.\n",
    "- Eğer yanlış negatifler (kalp hastalığı olan bireylerin sağlıklı olarak sınıflandırılması) daha büyük bir risk taşıyorsa, recall daha önemli olabilir. Örneğin, kalp hastalığı olan bir bireyin hastalığının tespit edilmemesi, hayati tehlikelere yol açabilir.\n",
    "\n",
    "\n",
    "- Kalp hastalığı olan birinin sağlıklı olarak sınıflandırılmaması gerektiği düşünüldüğünden ilk değerlendirme metriği olarak **RECALL** seçilmiştir.\n",
    "\n",
    "\n",
    "İkinci metrik olarak **ROC AUC score** seçilmiştir. ROC AUC score, modelin tüm sınıfları (hem pozitif hem de negatif) doğru şekilde ayırt etme yeteneğini değerlendirir. Bu, yanlış pozitifler ve yanlış negatifler (duyarlılık ve özgüllük -(sensitivity and specificity)) arasında bir denge kurmaya odaklanır.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Değerlendirme Fonksiyonunu Tanımlama**\n",
    "\n",
    "Tüm model eğitim ve değerlendirme sürecini kolay ve hatasız hale getirmek için bir fonksiyon içinde gerçekleştirilmiştir. Bu fonksiyon modeli, bölünmüş verileri, cross-validation fonksiyonunu ve score fonksiyonunu parametre olarak alır ve eğitimli modeli, eğitim ve doğrulama puanlarını içeren dataframe'i, nihai test puanını ve test seti üzerindeki tahminleri döner. Eğer plot parametresi True olarak belirtilirse, eğitim ve doğrulama sonuçlarını çizer. Eğitim verileri üzerinde cross-validation uygulamak, model değerlendirme aşamasında sıkça tercih edilen bir yöntemdir. Bu şekilde, modelin eğitim, doğrulama ve test seti üzerindeki sonuçlarını karşılaştırarak aşırı uyum (overfitting) ve yetersiz uyum (underfitting) durumlarını daha kolay gözlemlenebilir ve hiperparametreler bu sonuçlara göre ayarlayabilir. Ayrıca, problem sınıflandırma ise fonksiyon, confusion matrix'i de yazdırır. sklearn'deki karmaşıklık matrisi, modelin doğru negatif, yanlış pozitif tahminlerini birinci satırda ve yanlış negatif, doğru pozitif tahminlerini ikinci satırda gösterir.\n",
    "\n",
    "![Local Image](./confusion.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test,score_func, cv_type, plot=True):\n",
    " \n",
    "    # score listelerinin tanımanması\n",
    "    train_scores = []\n",
    "    validation_scores = []\n",
    "    score_per_fold = []\n",
    "    fold = 1\n",
    "\n",
    "    # overfitting underfitting tespiti için cross validation aşaması\n",
    "    for train_index, test_index in cv_type.split(X_train,y_train):\n",
    "        X_train_cv, X_validation_cv = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_cv, y_validation_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # cross validation eğitim seti model fit \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_train = model.predict(X_train_cv)\n",
    "        y_pred_validation = model.predict(X_validation_cv)\n",
    "        \n",
    "        # eğitim scorlarının hesaplanması\n",
    "        train_score = score_func(y_train_cv, y_pred_train)\n",
    "        \n",
    "        # validation scorelarıın hesaplanması\n",
    "        validation_score = score_func(y_validation_cv, y_pred_validation)\n",
    "\n",
    "        # scoreların listelere eklenmesi\n",
    "        train_scores.append(train_score)\n",
    "        validation_scores.append(validation_score)\n",
    "\n",
    "        # socreların her fold için yazdırılması\n",
    "        print(f'Fold {fold} eğitim_{score_func.__name__}: {train_score:.2f}')\n",
    "        print(f'Fold {fold} validasyon_{score_func.__name__}: {validation_score:.2f}')\n",
    "\n",
    "        fold += 1\n",
    "        # fold sayısının listeye eklenmesi\n",
    "        score_per_fold.append(fold)\n",
    "\n",
    "    print(\"Cross validation aşaması tamamlandı! Model eğitimine başlandı...\")\n",
    "\n",
    "    # Cross validasyon aşaması tamamlandıktan sonra modelin tüm veri seti üzerinde tekrar eğitilmesi\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"*******************************************\")\n",
    "    print(\"Model eğitimi tamamlandı!\")\n",
    "    print(\"*******************************************\")\n",
    "\n",
    "    # test seti üzerinde tahmin yapılması ve eğer skor fonksiyonunun adı `roc_auc_score` ise, 1 sınıfına ait tahmin edilen olasılıkların alınması.\n",
    "    if score_func.__name__ == \"roc_auc_score\":\n",
    "        y_pred_test = model.predict_proba(X_test)[:,1]\n",
    "    else:\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # En son test seti üzerinde score hesaplanması\n",
    "    final_test_score = score_func(y_test, y_pred_test)\n",
    "\n",
    "    # scoreların sözlüğe kaydedilmesi\n",
    "    scores_dict = {\n",
    "    \"fold\": range(1, len(score_per_fold) + 1),\n",
    "    f\"eğitim_{score_func.__name__}\": train_scores,\n",
    "    f\"validasyon_{score_func.__name__}\": validation_scores\n",
    "    }\n",
    "    \n",
    "    # plot için df oluşturulması\n",
    "    scores_df = pd.DataFrame(scores_dict)\n",
    "    \n",
    "    # validasyon scorunun eğitim scoruna göre farkının % değeri.\n",
    "    percentage_difference_train_valid = ((np.mean(validation_scores) - np.mean(train_scores)) / np.mean(train_scores)) * 100\n",
    "\n",
    "    # final scoreun eğitim scoruna göre farkının % değeri.\n",
    "    percentage_difference_train_test = ((final_test_score - np.mean(train_scores)) / np.mean(train_scores)) * 100\n",
    "\n",
    "    print(f\"Ortalama eğitim_{score_func.__name__} sonuç: {np.mean(train_scores):.2f}\")\n",
    "    print(f'Ortalama validasyon_{score_func.__name__} sonuç: {np.mean(validation_scores):.2f}')\n",
    "    print(f'Son test_{score_func.__name__} sonuç: {final_test_score:.2f}')\n",
    "    print(f'Validasyon scorunun eğitim scoruna göre farkının % değeri:%{percentage_difference_train_valid:.2f}')\n",
    "    print(f'Final scoreun eğitim scoruna göre farkının % değeri:%{percentage_difference_train_test:.2f}')\n",
    "    # it prints confusion matrix if the problem is classification\n",
    "    if score_func.__name__ in [\"precision_score\",\"recall_score\",\"f1_score\"]:\n",
    "        cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "        print(f\"Son test seti için oluşturulan confusion matrix:\\n {cf_matrix}\")\n",
    "\n",
    "    print(\"*******************************************\")\n",
    "\n",
    "    if plot:\n",
    "        sns.lineplot(data=scores_df, x=\"fold\", y=f\"eğitim_{score_func.__name__}\", marker=\"o\", label=f\"eğitim_{score_func.__name__}\")\n",
    "        sns.lineplot(data=scores_df, x=\"fold\", y=f\"validasyon_{score_func.__name__}\", marker=\"v\", label=f\"validasyon_{score_func.__name__}\")\n",
    "        plt.xlabel(\"Fold\")\n",
    "        plt.ylabel(f\"{score_func.__name__}\")\n",
    "        plt.title(f\"Her folddaki {score_func.__name__}\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return  model, final_test_score, scores_df, y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Eğrisi Fonksiyonunu Tanımlama**\n",
    "\n",
    "ROC eğrisi, bir ikili sınıflandırma modelinin performansını farklı eşik değerlerinde grafiksel olarak gösterir. Bu eğri, gerçek pozitif oranını (TPR) yanlış pozitif oranına (FPR) karşı çizer. TPR, modelin gerçek pozitif vakaları ne kadar doğru tespit ettiğini ölçerken, FPR, modelin negatif vakaları yanlış bir şekilde pozitif olarak sınıflandırma oranını ölçer. ROC eğrisi, sınıflandırıcının karar eşiği değiştikçe TPR ve FPR arasındaki dengeyi görselleştirir. Eğri Altındaki Alan (AUC), eğrinin altındaki alanı temsil eder ve modelin genel performansını ölçmek için kullanılır. Bu nedenle, ROC eğrisi ve AUC, ikili sınıflandırma modellerinin performansını değerlendirmek ve karşılaştırmak için önemli araçlardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred_prob):\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
    "\n",
    "    # Compute Area Under Curve (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color=\"teal\", lw=2, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color=\"lightsteelblue\", lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Veri setinin eğitim ve test olarak bölünmesi ve SMOTE oversampling uygulanması**\n",
    "\n",
    "**Veri setinde presence_of_heart_disease hedef değişkeninde sınıf dengesizliği bulunmaktadır.**\n",
    "\n",
    "- Sınıf dengesizliğini ele almak için 4 yöntem uygulanmıştır.\n",
    "  \n",
    "- 1. Bölme işleminde stratify parametresi kullanılmıştır. train_test_split fonksiyonu bölme yaparken bunu dikkate alır.\n",
    "  \n",
    "- 2. Kullanılan modellerde class_weight parametresi balanced yapılmıştır.\n",
    "  \n",
    "- 3. Sınıf dengesizliğinde sıklıkla kullanılan **SMOTE** oversampling metodu kullanılmıştır.\n",
    "  \n",
    "- 4. Cross validation fonksiyonu olarak Stratified Kfold kullanılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical_feature(df, \"presence_of_heart_disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "**SMOTE (Synthetic Minority Over-sampling Technique)**\n",
    "\n",
    "SMOTE, dengesiz veri setlerinde azınlık sınıfının örneklerini artırmak için kullanılan bir over-sampling yöntemidir. Bu teknik, mevcut azınlık sınıfı örnekleri arasındaki farkları kullanarak sentetik örnekler oluşturur ve böylece sınıflar arasındaki dengesizliği azaltır.\n",
    "\n",
    "**Çalışma şekli:**\n",
    "1. **K En Yakın Komşu**: Her bir azınlık sınıfı örneği için k en yakın komşu belirlenir.\n",
    "2. **Yeni Örnekler Oluşturma**: Rastgele bir komşu seçilir ve bu komşu ile mevcut örnek arasındaki vektör boyunca yeni bir örnek oluşturulur.\n",
    "3. **Oversampling**: Bu adımlar tekrarlanarak veri setine yeni sentetik azınlık sınıfı örnekleri eklenir.\n",
    "\n",
    "**Avantajları:**\n",
    "- **Dengesiz Verilerin Dengelenmesi**: Azınlık sınıfı örneklerini artırarak veri setindeki sınıf dengesizliğini azaltır.\n",
    "- **Overfitting'i Azaltma**: Yeni örnekler oluştururken sadece mevcut örnekleri tekrar etmek yerine yeni sentetik örnekler üreterek overfitting riskini azaltır.\n",
    "  \n",
    "**SMOTE, eğitim setindeki azınlık sınıfı örneklerini artırarak modelin bu sınıfı daha iyi öğrenmesini sağlar. Ancak, test seti modelin performansını değerlendirmek için kullanılır ve bu set üzerinde herhangi bir müdahale yapılmamalıdır. Test seti, modelin eğitim süreci dışında kalmalı ve gerçek dünya performansını yansıtmalıdır.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Özellik seçim ve verilerin bölünmesi**\n",
    "- Verilerin bölünmesinde test size seçimi önemli ayarlamalardan bir tanesidir.\n",
    "- Test boyutu seçiminde %10, %12, %15, %20 ve %25 değerleri kullanılmış model değerlendirme fonksiyonunda uygulanmıştır. En eğitim, validasyon ve final scorelara göre en uygun test boyutu %12 seçilmiştir(eğitim recall = 0.88, validation recall=0.89, test recall=0.90- scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///C:/Users/iskorpittt/Desktop/MY_DATA_SCIENCE/PROJECTS/kodlasam_project/mlruns\")\n",
    "\n",
    "mlflow.set_experiment(\"heart_disease_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"presence_of_heart_disease\"\n",
    "columns_that_will_not_used = [\"presence_of_heart_disease\"]\n",
    "features = [col for col in df.columns if col not in columns_that_will_not_used]\n",
    "X = df[features]\n",
    "y= df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "y_train.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE işlemi sonucunda X_train satır sayısı 261, den 376'ya çıkmış sentetik datalar üretilmiştir.\n",
    "- SMOTE öncesi %72 0, %28 1 değeri varken, işlem uygulandıktan sonra %50, %50 olacak hale gelmiştir.\n",
    "- SMOTE işlemi sadece eğitim setine uygulanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_smote.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train_smote.shape)\n",
    "print(y_test.shape)\n",
    "y_train_smote.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelleme**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lojistik Regresyon Modeli**\n",
    "\n",
    "Yüksek oranda sağa çarpıtılmış veriler, modelin daha iyi performans göstermesi için ölçeklenmelidir. Bunun için, pipeline içinde `StandardScaler` kullanılmıştır.\n",
    "\n",
    "Veri sayısı çok büyük olmadığından, hiperparametre ayarlamaları için en doğru sonucu almak amacıyla GridSearchCV yöntemi kullanılmıştır. Bu süreç sonucunda, düzenleme C değeri 0.003 olarak ve ceza değeri l2 (ridge) olarak belirlenmiştir. Hedef değişkenimizde bir sınıf dengesizliği olduğu için, daha az etkili sınıfı daha fazla dikkate almak adına `class_weight=\"balanced\"` seçeneği tercih edilmiştir.\n",
    "\n",
    "- **C**: Lojistik regresyondaki düzenleme kuvveti parametresidir. Daha küçük değerler daha güçlü düzenlemeyi ifade eder ve model üzerindeki bireysel veri noktalarının etkisini azaltır.\n",
    "- **Penalty**: Lojistik regresyonda kullanılan düzenleme cezasının türüdür. \"l2\" Ridge düzenlemesini ifade eder, bu düzenleme katsayıların karelerinin büyüklüğünü cezalandırarak daha küçük katsayı değerlerini teşvik eder.\n",
    "\n",
    "Sınıf dengesizliğini ele almak için çapraz doğrulama için StratifiedKFold seçilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression hyperparameter tuning**\n",
    "\n",
    "- Hyperparameter tuning için veri sayısı az olduğundan, brute force yöntemi ile bütün kombinasyonları deneyen Gridsearch kullanılmıştır. \n",
    "- Verisayısı ve parametre fazla olduğunda, bu yöntem kullanılamaz hale gelebilir. İşlem süreleri çok uzar. Böyle durumlarda Random search yada bayesian algoritmaları kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n",
    "scoring = make_scorer(recall_score) \n",
    "lr_cv = LogisticRegression()\n",
    "\n",
    "lr_pipeline_cv = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", lr_cv)\n",
    "])\n",
    "\n",
    "params_lr = {\n",
    "    \"classifier__penalty\": [\"l1\", \"l2\",\"elasticnet\"],\n",
    "    \"classifier__C\": [0.0001, 0.001, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 10, 100, 200],\n",
    "    \"classifier__class_weight\": [\"balanced\"] \n",
    "} \n",
    "\n",
    "with mlflow.start_run(run_name=\"GridSearchCV Logistic Regression\"):\n",
    "\n",
    "    grid_rf = GridSearchCV(estimator=lr_pipeline_cv,param_grid=params_lr,cv=skf,scoring=scoring,verbose=1,n_jobs=1)\n",
    "    grid_rf.fit(X,y)\n",
    "    best_hyperparams_lr = grid_rf.best_params_\n",
    "    best_score_lr = grid_rf.best_score_\n",
    "    print(\"Logistic Regression için en iyi hiperparametreler:\", best_hyperparams_lr)\n",
    "    print(\"Logistic Regression için en iyi score(recall):\", best_score_lr)\n",
    "    \n",
    "    # Hyperparametreleri ve en iyi skorların mlflow'a kaydedilmesi\n",
    "    mlflow.log_params(best_hyperparams_lr)\n",
    "    mlflow.log_metric(\"lr_best_recall_score\", best_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "**Verisetinde denenen ölçekleme yöntemleri**\n",
    "\n",
    "#### MinMaxScaler\n",
    "**MinMaxScaler**, veriyi belirli bir aralıkta (genellikle 0 ile 1 arasında) ölçekler. Bu ölçekleme, verinin minimum ve maksimum değerleri kullanılarak yapılır.\n",
    "\n",
    "- **Formül:**\n",
    "  $$\n",
    "  z = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "  $$\n",
    "\n",
    "#### StandardScaler\n",
    "**StandardScaler**, veriyi ortalama 0 ve standart sapma 1 olacak şekilde ölçekler. Bu, verinin dağılımını merkezler ve ölçekler.\n",
    "\n",
    "- **Formül:**\n",
    "  $$\n",
    "  z = \\frac{x - \\mu}{\\sigma}\n",
    "  $$\n",
    "\n",
    "#### RobustScaler\n",
    "**RobustScaler**, veriyi medyan ve yüzde değer aralıkları kullanarak ölçekler. Bu ölçekleme yöntemi, aykırı değerlere karşı daha dayanıklıdır.\n",
    "\n",
    "- **Formül:**\n",
    "  $$\n",
    "  z = \\frac{x - \\text{medyan}}{IQR}\n",
    "  $$\n",
    "\n",
    "\n",
    "- Sayısal verilerde aykırı değer analizi yapılmış ve aykırı değerler baskılanmıştır. Fakat yinede V sağa ve sola çarpık özellikler bulunmaktadır.Linear modellerde bunlar bozucu etki yapabilir ve model performansını olumsuz etkiler.\n",
    "- Bu nedenle verileri uygun bir ölçeğe getirmek model performansını artırabilir.\n",
    "- Aykırı değer işlemleri yaptığımızdan ve çok aşırı çarpıklıklar olmadığından `StandarScaler` yöntemi kullanılabilir. \n",
    "- Yinede 3 yöntem denenmiş en uygun olarak `StandarScaler` en iyi scoreları vermiştir.\n",
    "- Logistic regression modelinde `StandarScaler` uygulandıktan sonra Recall test scoru 0.80 den, 0.90 ' a yükselmiştir. \n",
    "  \n",
    "- **!!!Not: Bu sonuçlar baseline model aşamasında elde edilmiştir. Feature ekledikten sonra sonuçlar değişmiştir.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling olmadan model eğitim ve değerlendirmesi**\n",
    "\n",
    "- Ortalama eğitim_recall_score sonuç: 0.77\n",
    "- Ortalama validasyon_recall_score sonuç: 0.75\n",
    "- Son test_recall_score sonuç: 0.80\n",
    "- Validasyon scorunun eğitim scoruna göre farkının % değeri:%-2.74\n",
    "- Final scoreun eğitim scoruna göre farkının % değeri:%2.48\n",
    "- Son test seti için oluşturulan confusion matrix:%3.26\n",
    " - [[19  7]\n",
    " - [ 2  8]]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search sonrası bulunan en iyi parametreler modele eklendi.\n",
    "\n",
    "lr = LogisticRegression(C=0.005, class_weight=\"balanced\", penalty=\"l2\")\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Not Scaled Model: Metric = recall\"):\n",
    "    skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n",
    "    lr_model, lr_final_test_recall_score, lr_recall_scores_df,lr_y_pred_test = train_and_evaluate_model(lr, X_train, y_train, X_test, y_test,recall_score, skf, plot=True)\n",
    "    \n",
    "    # Model metriklerin kaydedilmesi\n",
    "    mlflow.log_metric(\"final_test_recall_score\", lr_final_test_recall_score)\n",
    "    \n",
    "    # Modelin kaydedilmesi\n",
    "    model_path = \"logistic_regression_not_scaled_model\"\n",
    "    mlflow.sklearn.log_model(lr_pipeline, model_path)\n",
    "    \n",
    "    # Modeli Model Registry'ye kaydetme\n",
    "    mlflow.register_model(model_uri=f\"runs:/{mlflow.active_run().info.run_id}/{model_path}\", name=\"logistic_regression_not_scaled_model\")\n",
    "    \n",
    "    # Artifacts kayıt\n",
    "    lr_recall_scores_df.to_csv(\"mlflow_model_csv_data/lr_not_scaled_recall_scores.csv\", index=False)\n",
    "    mlflow.log_artifact(\"mlflow_model_csv_data/lr_not_scaled_recall_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling ile model eğitim ve değerlendirmesi**\n",
    "\n",
    "- Ortalama eğitim_recall_score sonuç: 0.88\n",
    "- Ortalama validasyon_recall_score sonuç: 0.89\n",
    "- Son test_recall_score sonuç: 0.90\n",
    "- Validasyon scorunun eğitim scoruna göre farkının % değeri:%1.26\n",
    "- Final scoreun eğitim scoruna göre farkının % değeri:%2.48\n",
    "- Son test seti için oluşturulan confusion matrix:\n",
    " - [[21  5]\n",
    " - [ 1  9]]\t\n",
    " - Confusion matrixde sadece 1 kişi FN yani yanlış teşhis konulmuş, TP= 9 kişi kalp hastası olarak sınıflandırılmıştır. Model amaca uygun sonuçlar üretmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search sonrası bulunan en iyi parametreler modele eklendi.\n",
    "lr = LogisticRegression(C=0.005, class_weight=\"balanced\", penalty=\"l2\")\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"classifier\", lr)\n",
    "])\n",
    "\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Scaled Model: Metric = recall\"):\n",
    "    skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)\n",
    "    lr_model, lr_final_test_recall_score, lr_recall_scores_df,lr_y_pred_test = train_and_evaluate_model(lr_pipeline, X_train, y_train, X_test, y_test,recall_score, skf, plot=True)\n",
    "    \n",
    "    # Model metriklerin kaydedilmesi\n",
    "    mlflow.log_metric(\"final_test_recall_score\", lr_final_test_recall_score)\n",
    "    \n",
    "    # Modelin kaydedilmesi\n",
    "    model_path = \"logistic_regression_scaled_model\"\n",
    "    mlflow.sklearn.log_model(lr_pipeline, model_path)\n",
    "    \n",
    "    # Modeli Model Registry'ye kaydetme\n",
    "    mlflow.register_model(model_uri=f\"runs:/{mlflow.active_run().info.run_id}/{model_path}\", name=\"logistic_regression_scaled_model\")\n",
    "    \n",
    "    # # Artifacts kayıt\n",
    "    lr_recall_scores_df.to_csv(\"mlflow_model_csv_data/lr_scaled_recall_scores.csv\", index=False)\n",
    "    mlflow.log_artifact(\"mlflow_model_csv_data/lr_scaled_recall_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
